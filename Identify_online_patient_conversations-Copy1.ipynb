{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "from IPython.display import HTML, display, SVG\n",
    "from IPython.core import display as ICD\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "import math\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding, GRU\n",
    "from keras.regularizers import L1L2\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator_shuffle(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    np.random.shuffle(index)\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:]\n",
    "        y_batch = y_data[index_batch]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "@as_keras_metric\n",
    "def auc_pr(y_true, y_pred, curve='PR'):\n",
    "    return tf.metrics.auc(y_true, y_pred, curve=curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FOLDER = 'dataset/'\n",
    "OUTPUT_FOLDER = 'Models_and_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(SOURCE_FOLDER + 'train.csv', encoding='ISO-8859-1')\n",
    "test_data = pd.read_csv(SOURCE_FOLDER + 'test.csv', encoding='utf8')\n",
    "test_data = test_data[test_data.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['TRANS_CONV_TEXT'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efd76c36160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le.fit(train_data.Source)\n",
    "train_source = le.transform(train_data.Source)\n",
    "\n",
    "train_data.Patient_Tag.value_counts().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['TRANS_CONV_TEXT']\n",
    "Y_train = train_data['Patient_Tag']\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, stemmer, lemma):\n",
    "    preprocessed_data = []\n",
    "    trans = str.maketrans('/(){}', ' ' * 5)\n",
    "    trans_punc = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    for text in X_train:\n",
    "        text = text.lower().translate(trans)\n",
    "        text = text.translate(trans_punc)\n",
    "        text = [lemma.lemmatize(word) for word in text.split()]\n",
    "        preprocessed_data.append(' '.join(text))\n",
    "\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocess_data(X_train, stemmer, lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i went through a sleep study ahi severe at 95 and titration test in late 2011 but wa never able to sleep effectively i own the system one series 50 650 bipap pro that i wa prescribed and an opus 360 nasal pillow assembly both are essentially unused im about 20 pound lighter than i wa back then and my sleeping seems to be a little bit better now than it wa back then whats the best way of trying to address my sleep apnea again is it ok to just try my existing machine and setting and adjust using sleepyhead do i need to go back to the doc and or do another sleep study are there any particularly good mask since 2011 that might be better than what i have ive spent the last three week dealing with a father with congestive heart failure and id like to try and do what i can to avoid that'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(preprocessed_data)\n",
    "encoded_lines = t.texts_to_sequences(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = len(t.word_index) + 1\n",
    "max_length_of_input = 600\n",
    "embedding_vector_length = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(encoded_lines, max_length_of_input)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(number_of_words, embedding_vector_length, input_length = max_length_of_input))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "Epoch 1/40\n",
      "25/24 [===============================] - 34s 1s/step - loss: 0.5650 - auc_pr: 0.7297 - acc: 0.7808 - val_loss: 0.4971 - val_auc_pr: 0.7784 - val_acc: 0.7906\n",
      "Epoch 2/40\n",
      "25/24 [===============================] - 33s 1s/step - loss: 0.4479 - auc_pr: 0.8102 - acc: 0.7906 - val_loss: 0.3845 - val_auc_pr: 0.8489 - val_acc: 0.7880\n",
      "Epoch 3/40\n",
      "25/24 [===============================] - 41s 2s/step - loss: 0.2160 - auc_pr: 0.8801 - acc: 0.9147 - val_loss: 0.4453 - val_auc_pr: 0.8967 - val_acc: 0.8508\n",
      "Epoch 4/40\n",
      "25/24 [===============================] - 37s 1s/step - loss: 0.0915 - auc_pr: 0.9110 - acc: 0.9762 - val_loss: 0.3977 - val_auc_pr: 0.9244 - val_acc: 0.8717\n",
      "Epoch 5/40\n",
      "25/24 [===============================] - 36s 1s/step - loss: 0.0234 - auc_pr: 0.9342 - acc: 0.9912 - val_loss: 0.4473 - val_auc_pr: 0.9420 - val_acc: 0.8743\n",
      "Epoch 6/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 0.0050 - auc_pr: 0.9475 - acc: 1.0000 - val_loss: 0.4327 - val_auc_pr: 0.9527 - val_acc: 0.8848\n",
      "Epoch 7/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 0.0054 - auc_pr: 0.9565 - acc: 0.9987 - val_loss: 0.4682 - val_auc_pr: 0.9597 - val_acc: 0.8874\n",
      "Epoch 8/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 0.0018 - auc_pr: 0.9621 - acc: 1.0000 - val_loss: 0.5139 - val_auc_pr: 0.9642 - val_acc: 0.8770\n",
      "Epoch 9/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 0.0014 - auc_pr: 0.9658 - acc: 1.0000 - val_loss: 0.5474 - val_auc_pr: 0.9673 - val_acc: 0.8770\n",
      "Epoch 10/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 9.6558e-04 - auc_pr: 0.9684 - acc: 1.0000 - val_loss: 0.5754 - val_auc_pr: 0.9695 - val_acc: 0.8796\n",
      "Epoch 11/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 7.8798e-04 - auc_pr: 0.9703 - acc: 1.0000 - val_loss: 0.5757 - val_auc_pr: 0.9711 - val_acc: 0.8770\n",
      "Epoch 12/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 5.6814e-04 - auc_pr: 0.9717 - acc: 1.0000 - val_loss: 0.5882 - val_auc_pr: 0.9723 - val_acc: 0.8796\n",
      "Epoch 13/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 4.7671e-04 - auc_pr: 0.9728 - acc: 1.0000 - val_loss: 0.5984 - val_auc_pr: 0.9732 - val_acc: 0.8796\n",
      "Epoch 14/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 4.3476e-04 - auc_pr: 0.9736 - acc: 1.0000 - val_loss: 0.6089 - val_auc_pr: 0.9739 - val_acc: 0.8822\n",
      "Epoch 15/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 3.5357e-04 - auc_pr: 0.9743 - acc: 1.0000 - val_loss: 0.6194 - val_auc_pr: 0.9745 - val_acc: 0.8796\n",
      "Epoch 16/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 3.3113e-04 - auc_pr: 0.9749 - acc: 1.0000 - val_loss: 0.6295 - val_auc_pr: 0.9751 - val_acc: 0.8848\n",
      "Epoch 17/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 3.5244e-04 - auc_pr: 0.9754 - acc: 1.0000 - val_loss: 0.6044 - val_auc_pr: 0.9756 - val_acc: 0.8927\n",
      "Epoch 18/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 2.9790e-04 - auc_pr: 0.9758 - acc: 1.0000 - val_loss: 0.6260 - val_auc_pr: 0.9760 - val_acc: 0.8927\n",
      "Epoch 19/40\n",
      "25/24 [===============================] - 26s 1s/step - loss: 2.4139e-04 - auc_pr: 0.9762 - acc: 1.0000 - val_loss: 0.6434 - val_auc_pr: 0.9763 - val_acc: 0.8822\n",
      "Epoch 20/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 2.1018e-04 - auc_pr: 0.9765 - acc: 1.0000 - val_loss: 0.6528 - val_auc_pr: 0.9766 - val_acc: 0.8848\n",
      "Epoch 21/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.9323e-04 - auc_pr: 0.9768 - acc: 1.0000 - val_loss: 0.6598 - val_auc_pr: 0.9769 - val_acc: 0.8874\n",
      "Epoch 22/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 4.4070e-04 - auc_pr: 0.9770 - acc: 1.0000 - val_loss: 0.6588 - val_auc_pr: 0.9771 - val_acc: 0.8770\n",
      "Epoch 23/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 2.2504e-04 - auc_pr: 0.9772 - acc: 1.0000 - val_loss: 0.6846 - val_auc_pr: 0.9774 - val_acc: 0.8770\n",
      "Epoch 24/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 2.1223e-04 - auc_pr: 0.9775 - acc: 1.0000 - val_loss: 0.6860 - val_auc_pr: 0.9775 - val_acc: 0.8717\n",
      "Epoch 25/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.8687e-04 - auc_pr: 0.9776 - acc: 1.0000 - val_loss: 0.6901 - val_auc_pr: 0.9777 - val_acc: 0.8743\n",
      "Epoch 26/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.5024e-04 - auc_pr: 0.9778 - acc: 1.0000 - val_loss: 0.6953 - val_auc_pr: 0.9778 - val_acc: 0.8743\n",
      "Epoch 27/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.4265e-04 - auc_pr: 0.9779 - acc: 1.0000 - val_loss: 0.7002 - val_auc_pr: 0.9779 - val_acc: 0.8743\n",
      "Epoch 28/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.2743e-04 - auc_pr: 0.9780 - acc: 1.0000 - val_loss: 0.7077 - val_auc_pr: 0.9780 - val_acc: 0.8743\n",
      "Epoch 29/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.2711e-04 - auc_pr: 0.9780 - acc: 1.0000 - val_loss: 0.7076 - val_auc_pr: 0.9781 - val_acc: 0.8743\n",
      "Epoch 30/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.4673e-04 - auc_pr: 0.9781 - acc: 1.0000 - val_loss: 0.7212 - val_auc_pr: 0.9782 - val_acc: 0.8743\n",
      "Epoch 31/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.1209e-04 - auc_pr: 0.9782 - acc: 1.0000 - val_loss: 0.7290 - val_auc_pr: 0.9783 - val_acc: 0.8717\n",
      "Epoch 32/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.0124e-04 - auc_pr: 0.9783 - acc: 1.0000 - val_loss: 0.7354 - val_auc_pr: 0.9783 - val_acc: 0.8743\n",
      "Epoch 33/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 9.5497e-05 - auc_pr: 0.9783 - acc: 1.0000 - val_loss: 0.7410 - val_auc_pr: 0.9783 - val_acc: 0.8770\n",
      "Epoch 34/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 9.3211e-05 - auc_pr: 0.9784 - acc: 1.0000 - val_loss: 0.7450 - val_auc_pr: 0.9784 - val_acc: 0.8770\n",
      "Epoch 35/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 1.1313e-04 - auc_pr: 0.9784 - acc: 1.0000 - val_loss: 0.7316 - val_auc_pr: 0.9784 - val_acc: 0.8770\n",
      "Epoch 36/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 8.6136e-05 - auc_pr: 0.9784 - acc: 1.0000 - val_loss: 0.7369 - val_auc_pr: 0.9785 - val_acc: 0.8743\n",
      "Epoch 37/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 7.4760e-05 - auc_pr: 0.9785 - acc: 1.0000 - val_loss: 0.7463 - val_auc_pr: 0.9785 - val_acc: 0.8743\n",
      "Epoch 38/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 9.1104e-05 - auc_pr: 0.9785 - acc: 1.0000 - val_loss: 0.7400 - val_auc_pr: 0.9785 - val_acc: 0.8770\n",
      "Epoch 39/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 6.8068e-05 - auc_pr: 0.9785 - acc: 1.0000 - val_loss: 0.7379 - val_auc_pr: 0.9786 - val_acc: 0.8796\n",
      "Epoch 40/40\n",
      "25/24 [===============================] - 25s 1s/step - loss: 6.9049e-05 - auc_pr: 0.9786 - acc: 1.0000 - val_loss: 0.7449 - val_auc_pr: 0.9786 - val_acc: 0.8796\n",
      "382/382 [==============================] - 2s 5ms/step\n",
      "\n",
      "\n",
      "[0.7449118510590798, 0.9781570865221673, 0.8795811502721297]\n"
     ]
    }
   ],
   "source": [
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[auc_pr, 'accuracy'])\n",
    "\n",
    "mc = keras.callbacks.ModelCheckpoint('weights{epoch:02d}.h5', \n",
    "                                     save_weights_only=True, period=5)\n",
    "\n",
    "# Try 40 epochs\n",
    "model.fit_generator(generator=batch_generator_shuffle(X_train, y_train, 32),\n",
    "                      epochs=40, validation_data=(X_valid, y_valid),\n",
    "                      steps_per_epoch=X_train.shape[0] / 32, callbacks=[mc])\n",
    "\n",
    "scores = model.evaluate(X_valid, y_valid)\n",
    "print ('\\n')\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [0.626494295846403, 0.983139782170065, 0.8856209134743884]\n",
    "- 1 - 7: val_loss: 0.3521 - val_auc_pr: 0.9775 - val_acc: 0.8922\n",
    "- 2 - 200: val_loss: 0.6366 - val_auc_pr: 0.9851 - val_acc: 0.8889\n",
    "- 3 - val_loss: 1.3443 - val_auc_pr: 0.9714 - val_acc: 0.8246\n",
    "- 6 - val_loss: 0.8538 - val_auc_pr: 0.9799 - val_acc: 0.8796\n",
    "- 7 - val_loss: 0.9069 - val_auc_pr: 0.9755 - val_acc: 0.8848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data['TRANS_CONV_TEXT']\n",
    "X_test = preprocess_data(X_test, stemmer, lemma)\n",
    "X_test = t.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(X_test, max_length_of_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 3934,  743,  982],\n",
       "       [   0,    0,    0, ...,  929,  395,  176],\n",
       "       [   0,    0,    0, ..., 7374, 7375, 4014],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  114,  296,   35],\n",
       "       [   0,    0,    0, ...,   68,   12,    7],\n",
       "       [   0,    0,    0, ...,   26,  172,  668]], dtype=int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "model_35 = model.to_json()\n",
    "loaded_model_35 = model_from_json(model_35)\n",
    "loaded_model_35.load_weights(\"weights25.h5\")\n",
    "\n",
    "loaded_model_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model \n",
    "\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_test, 32)\n",
    "\n",
    "patient_tag = np.argmax(output, axis=1)\n",
    "index = list(range(1, len(output)+1))\n",
    "test_data_df = pd.DataFrame({'Index': index,'Patient_Tag': patient_tag}).set_index('Index')\n",
    "test_data_df.to_csv('output.csv', columns=['Patient_Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    454\n",
       "1    117\n",
       "Name: Patient_Tag, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.Patient_Tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(OUTPUT_FOLDER + \"15_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(OUTPUT_FOLDER + \"15_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    465\n",
       "1    106\n",
       "Name: Patient_Tag, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = pd.read_csv('Models_and_output/10_ensemble_output_92_99475.csv')\n",
    "out1.Patient_Tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#446 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04101691649275391"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.Patient_Tag.corr(out1.Patient_Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.read_csv(SOURCE_FOLDER + 'train.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Host</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date(ET)</th>\n",
       "      <th>Time(ET)</th>\n",
       "      <th>time(GMT)</th>\n",
       "      <th>Title</th>\n",
       "      <th>TRANS_CONV_TEXT</th>\n",
       "      <th>Patient_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORUMS</td>\n",
       "      <td>cafepharma.com</td>\n",
       "      <td>http://cafepharma.com/boards/threads/epstein.5...</td>\n",
       "      <td>6/15/2016</td>\n",
       "      <td>13:58:00</td>\n",
       "      <td>6/15/2016 23:28</td>\n",
       "      <td>Epstein</td>\n",
       "      <td>I don't disagree with you in principle. I'm ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORUMS</td>\n",
       "      <td>www.patient.co.uk</td>\n",
       "      <td>http://www.patient.co.uk/forums/discuss/enlarg...</td>\n",
       "      <td>5/7/2016</td>\n",
       "      <td>0.820833333</td>\n",
       "      <td>42498.21667</td>\n",
       "      <td>Enlarged Heart.Thread Enlarged Heart</td>\n",
       "      <td>I am always dizzy I get dizzy standing up so I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLOG</td>\n",
       "      <td>http://abcnewsradioonline.com/entertainment-news</td>\n",
       "      <td>http://abcnewsradioonline.com/entertainment-ne...</td>\n",
       "      <td>4/14/2016</td>\n",
       "      <td>15:00:38</td>\n",
       "      <td>4/15/2016 0:30</td>\n",
       "      <td>Queen Latifah Joins American Heart Association...</td>\n",
       "      <td>Axelle/Bauer-Griffin/FilmMagic(NEW YORK) -- Qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORUMS</td>\n",
       "      <td>www.cancer-forums.net</td>\n",
       "      <td>http://www.cancer-forums.net/viewtopic.php?f=1...</td>\n",
       "      <td>6/18/2016</td>\n",
       "      <td>20:46:00</td>\n",
       "      <td>6/19/2016 6:16</td>\n",
       "      <td>Bulaemia</td>\n",
       "      <td>I am 17 and I have been throwing up for about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FORUMS</td>\n",
       "      <td>www.diyaudio.com</td>\n",
       "      <td>http://www.diyaudio.com/forums/lounge/292252-d...</td>\n",
       "      <td>6/15/2016</td>\n",
       "      <td>3:26:00</td>\n",
       "      <td>6/15/2016 12:56</td>\n",
       "      <td>DIY Silver interconnects and RCAs???</td>\n",
       "      <td>Quote: Originally Posted by Boyan Silyavski Wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source                                              Host  \\\n",
       "0  FORUMS                                    cafepharma.com   \n",
       "1  FORUMS                                 www.patient.co.uk   \n",
       "2    BLOG  http://abcnewsradioonline.com/entertainment-news   \n",
       "3  FORUMS                             www.cancer-forums.net   \n",
       "4  FORUMS                                  www.diyaudio.com   \n",
       "\n",
       "                                                Link   Date(ET)     Time(ET)  \\\n",
       "0  http://cafepharma.com/boards/threads/epstein.5...  6/15/2016     13:58:00   \n",
       "1  http://www.patient.co.uk/forums/discuss/enlarg...   5/7/2016  0.820833333   \n",
       "2  http://abcnewsradioonline.com/entertainment-ne...  4/14/2016     15:00:38   \n",
       "3  http://www.cancer-forums.net/viewtopic.php?f=1...  6/18/2016     20:46:00   \n",
       "4  http://www.diyaudio.com/forums/lounge/292252-d...  6/15/2016      3:26:00   \n",
       "\n",
       "         time(GMT)                                              Title  \\\n",
       "0  6/15/2016 23:28                                            Epstein   \n",
       "1      42498.21667               Enlarged Heart.Thread Enlarged Heart   \n",
       "2   4/15/2016 0:30  Queen Latifah Joins American Heart Association...   \n",
       "3   6/19/2016 6:16                                           Bulaemia   \n",
       "4  6/15/2016 12:56               DIY Silver interconnects and RCAs???   \n",
       "\n",
       "                                     TRANS_CONV_TEXT  Patient_Tag  \n",
       "0  I don't disagree with you in principle. I'm ju...            0  \n",
       "1  I am always dizzy I get dizzy standing up so I...            1  \n",
       "2  Axelle/Bauer-Griffin/FilmMagic(NEW YORK) -- Qu...            0  \n",
       "3  I am 17 and I have been throwing up for about ...            1  \n",
       "4  Quote: Originally Posted by Boyan Silyavski Wa...            0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efd08b86e10>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_data.Patient_Tag.value_counts().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
